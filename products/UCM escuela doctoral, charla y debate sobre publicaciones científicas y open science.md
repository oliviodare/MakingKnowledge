SESION: **¿Qué es una publicación científica? Como generar una publicación científica. Tipos de publicaciones. Publicar en abierto: #OpenScience. Resultados negativos**.
>Los/as científicos/as publican sus resultados periódicamente mediante artículos originales y/o de revisión en revistas científicas internacionales de diferente prestigio para mostrar los resultados de su investigación. Antes de su publicación, y para asegurar la veracidad, la reproducibilidad y el interés de lo que se publica, estos trabajos son evaluados por otros/as investigadores/as, proceso que se conoce como “revisión por pares” o “peer review”. Una vez publicados, para acceder a dicho contenido, la comunidad investigadora debe pagar unas tasas lo que no siempre facilita el acceso fácil y gratuito a dichos trabajos. En las últimas décadas está cobrando relevancia el movimiento open access o acceso abierto a la ciencia cuyo objetivo es favorecer el acceso libre y gratuito a la información producida por los investigadores, así como su reutilización mediante dos modalidades principales: los repositorios y las revistas de acceso abierto. En esta sesión, enmarcada en las _jornadas de la carrera investigadora,_ los participantes son expertos de reconocido prestigio en estas temáticas y nos explicarán qué es una publicación científica, y qué tipos de publicaciones científicas existen, qué es la ciencia abierta, sus pros y sus contras, entre otros asuntos. Además se hablará sobre valor que tiene publicar resultados negativos para el progreso científico y las diferentes revistas donde se pueden publicar dichos resultados.

---

“Moments when the norms and forms of expert communication have been most in doubt are precisely those moments when scientific practicioners have sought –or been forced– to renegotiate their public status within a wider political landsapce."(Introduction,*The Scientific Journal,* page 3)
---

---

**Outlines de los otros speakers**
*ISIDRO: "El investigador y los nuevos modos de comunicación científica"*
>Se realiza una presentación práctica con fines didácticos de los actores, procesos y medios de la comunicación cientifica en la actualidad, haciendo especial mención a los necesidades, retos, problemas y probables futuros desarrollos a los que prestar atención. Se introducen algunos aspectos que serán desarrollados en profundidad por los siguientes ponentes.
>>Isidro F. Aguillo coordina el Laboratorio de Cibermetría en el Instituto de Políticas y Bienes Públicos (IPP) del Consejo Superior de Investigaciones Científicas (CSIC). Sus líneas de trabajo incluyen el desarrollo de indicadores de la actividad investigadora en la web, la evaluación y análisis de las iniciativas de acceso abierto y los procesos de comunicación científica a través de revistas electrónicas y repositorios institucionales.

*ALICIA: "Ciencia abierta, acceso abierto a publicaciones y gestión de datos de investigación. ¿Qué necesitamos saber para cumplir con los organismos financiadores?"*
>Se explicarán los conceptos principales relacionados con la ciencia abierta, el acceso abierto a las publicaciones y la gestión de los datos de investigación, destacando algunos desafíos y aclarando falsas creencias. Todos estos aspectos se tratarán teniendo especialmente en cuenta las obligaciones que tienen los investigadores frente a los organismos de los financiadores.
>>Alicia Fátima Gómez es Jefa del Grupo de Cienciometría y Visualización de Datos en la Universidad Técnica de Viena. Anteriormente ha trabajado en la FECYT para el proyecto OpenAIRE, en el CNIC (Madrid) como Responsable del Servicio de Biblioteca, y en Reino Unido como especialista en Comunicación Académica. Sus líneas de trabajo se centran en dar apoyo a investigadores y bibliotecas en aspectos como bibliometría, evaluación y visibilidad de la investigación, acceso abierto y ciencia abierta, gestión de datos de investigación y desarrollo de planes de gestión de datos.


---

**Puntos de interés**
- Ideas: Ecuador talk: https://medium.com/p/1928655d761e/edit
- ¿Qué es un artículo científico? Unidad de comunicación vs unidad de evaluación. El artículo como una unidad del sistema de recompensa, evaluativo y económico la ciencia.
- El no-éxito (i.e., Trial and Error) como ejemplo (resultados negativos, narrativas inacabadas, experimentos fallidos, resultados inesperados, ignorancia) > ¿qué camino atraviesan estos tipos de artículos en el régimen de publicación académica actual?
- *Journal of Trial and Error* no como solución, sino ejemplo de las posibilidades de auto-organización de los científicos jóvenes.
- ‘Science Fails, Let’s Publish’
	- Failures
		- Self image and public image of science (Big Men vs Community), what is researched and what is published (Discovery, success vs fine-tuning, messy), Gap between what is popular and research that is replicable (impact vs replicability).
	- Report & Reflection: beyond a database, the need for transdisciplinary reflection: HPS/STS
	- Costs of publication structures: why WE can do this.
-  Estandarización del formato (IMRD) --> pérdida de la representación del proceso científico --> necesdidad de volver hacia la narración en la ciencia
-  #OpenAccess: not #OpenScience 
	-  9500 is not OS (and not even OA)
	-  why is specialized OA important, when you have sci-hub?
	-  OS in not the end, but the means (self-reflection and the possibility of grassroots thanks to the power of the internet as the only good thigs)
	- Revistas depredadoras: no problematicas
	- auto-organización, presión política, resistencia
	- volver y/o reforzar el modelo de sociedades
- Tips: self-organisation, connected papers, GAMING THE METRICS, ALEX CSISZAR

---

**Outline talk**

- Reflexiones sobre qué es una publicación científica
	- Mensaje princial: la publicación científica no es una unidad de comunicación o de conocimiento, la publicación científica es una unidad de evaluación y de contabilidad. 
	- Tocaré otros temas: la ciencia como trabajo, #OpenScience #OpenAccess, la importancia y el papel del formato de la publicación científica, mi visión sobre las llamadas malas prácticas y revistas depredadoras
	-  Recomendaciones específicas



Bien, por 'reflexionar', me refiero a dar un paso atrás, tomar un poco de perspectiva, y poner las cuestiones de las que los ponentees han hablado hoy desde un punto de vista histórico y sociológico. Creo que es importante que entendamos bien *qué* es una publicación académica antes de adentrarlos a entender *cómo* producirla o que *tipos* y *modos* de publicaciones existen. 

Cómo he dicho al principio, lo que quiero transmitiros es que la publicación científica no es una unidad de conocimiento, sino de evaluación. Pero esto no ha sido siempre así. Detrás de esto ha habido un proceso (relativamente corto, de hecho) de lo que me gustaría llamar devaluación del artículo como unidad comunicativa. 

¿Porqué se han unido en esta charla el movimento de la Ciencia Abierta y la publicación científica? ¿Que tipo de relación hay entre las dos? La relación entre las dos es histórica. Desde los años 90 ha habido tres procesos que han provocado la "tormenta perfecta" que ha desencadnado tanto la devaluación del artículo científico, como el surgimiento del lllamado moviento del Open Science. Estos procesos han sido 
1. **La revolución de Internet**: con la que la materialidad del papel desapareció, haciendo posible la difusión rápida y global de artículos. 
2. **La transformación económica de publicación académica**: un creciente monopolio de casas editoriales con el consecuento incremento en el precio de subscripciones, a la vez que un incremento exponencial del número de artículos y revistas especialistas. 
3. **El giro evaluativo**: el proceso por el cual se impulsó la evaluación de la efectividad y producitividad de una decreciente inversión pública en la ciencia, un proceso que se ideó en los años 70 y se empezó a establecer en sectores públicos en los 80 y 90. Los mecanismos de concesión de financiaciamento se transformaron de una revisión por pares acusada de favoritismo, nepotismo, y subjetivismo, sustituida por una supuesta evaluación objetiva, parcial, y justa a través de datos bibliométricos. 

Estos tres elementos y la interación entre ellos fue lo que provocó el surgimiento del Open Science: la demanda de un acceso gratuito a publicaciones científicas y la demanda de unos sistemas de evaluación justos y quantificables. 

Antes de hablar de estos procesos, y sobre qué ha cambiado desde los años 90, creo que debemos ir más atrás. Debemos tener en mente otro contexto. Además de cambios, debemos hablar también de lo que *no* ha cambiado. Porque algo  no a cambiado desde los años 70 en la ciencia –de hecho, *nunca* ha cambiado. Esto es, que los científicos se deben a un patrón. Antes del siglo XVIII eran los hombres ricos quien hacían o financiaban ciencia. Estos eran los realmente patrones, que financiaban ciencia que les interesaba tanto por razones militares, políticas, o religiosas. Sólo fue a partir del siglo XIX que el Estado empezó a involucrarse en la financiación, y en el siglo XX fue la inversión comercial privada. Pero ahora bien, a pesar de estos cambios, a pesar de cambios en *quien* paga la factura, algo no ha cambiado: la factura y que hay alguien que la paga. Siempre ha habido y *hay* un patrón: **el trabajo sigue siendo trabajo**, los científicos nunca son independientes, en ningún lugar del mundo, en ninguna de las épocas de la ciencia moderna. Siempre hay un patrón. Y con este patrón, cierto modelo económico que determina la forma, el contenido, y la valorización del artículo científicos. 

Bien, con esta pequeña pausa donde podemos ver cierta *continuidad* histórica, vamos a ver ahora las *diferencias* desde los años 90 que han posibilitado tanto el surgiemiento de la Ciencia Abierta cómo de la devaluación del artículo científico como unidad de comunciación.

En este gráfico podemos ver uno de los modelos más populares y efectivos que explicaban que era una publicación científica *antes* de los años 90 y los procesos de los que hemos hablado. Es un modelo que explica la relación entre el artículo científico y los recursos a disposición de grupos o individuos. Es un modelo relativemente simple, dónde la publicación de un artículo en una revista, mediada por la aceptación por parte de los colegas de profesión, permite la presentación del artículo como una unidad de conocimiento. El artículo aquí funciona como una pieza dentro del proceso de investigación de todos los científicos. Es esta pieza que será (o no) citada, premiada, alabada, rebatida, o olvidada. Dentro de este modelo, que explicaba la situación academica pre-años 90, el artículo como unidad de conocimiento, permitía, a través de capital simbólico (sea formal como las citaciones o informal como la fama) la acumulación de nuevos recursos para la investigación.

Ahora bien, como ya hemos dicho, hubo tres procesos interconectados(Internet, la transformación económica del ecosistema de publicaciones, la tendencia evaluativa) a partir de los años 90 que crearon un cambio en  este modelo. El modelo ya no servía, pues se habían introducido nuevos elementos en el ecosistema y habían crecido nuevas interacciones.

Para empezar, la posibilidad de publicar online y electrónicamente facilitó la multiplicación tanto de papers como de revistas, lo que hacía más dificl una evaluación personal, subjectiva, del *valor* de esos artículos. Eso llevó tanto a una cris de evaluación, que facilitó el nacimiento de disciplinas nuevas como el scientometrics, pero también de los llamados 'predatory journals'. No vamos a meternos en los detalles de estas interacciones y de este nuevo modelo de la relación entre artículo y recursos. Sólo cabe decir que la obtención de capital simbólico se ha hecho mucho más compleja, donde no entra solamente que tu artículo sea bien visto por tus colegas, sino una serie de elementos cuantificables y externos en los que el científico como individuo tiene poco control. 


Como veis, los procesos que han llevado al nacimiento de las revistas predadoras son los mismos que los que han llevado al nacimiento del scientometrics: internet, la ciencia siendo evaluada, y el creciente monopolio editorial. Pero ¿cual es el problema de los predatory journals? En mi opinión, ninguno. Primero, aquellos que caen en emails como este, no caen, lo eligen. 



Segundo, incluso si alguien publica sus estudios en una revista predatora, sin revisores, ¿cuál es el problema? Muchos, muchos, muchos artículos y libros que sirven como fundamento científico no han tenido revisión por pares. La revisión por pares es un fenómeno moderno que no garantiza la veracidad de un artículo. Si la ciencia no está bien, si las declaraciones de veracidad que se pueden hacer no son correctos, ¿cuál es el problema? En mi opinión ninguno. Si la estructura de la ciencia global se ve amenazada por cuatro revistas indias publicando por dinero, creo que realmente la ciencia tiene un problema. Pero realmente, las revistas depredadoras no son problema alguna. Sinceramente, creo que los artículos comprados en revistas predatoras no ponen ningún riesgo a la integridad global. Las revistas predatoras, de lo que si sirven, es para especificar e individualizar un miedo concreto de los científicos: la relación entre trabajo y objetiviad. Porque realmente, la razón por la cual las revistas predatoras existen es para dar citaciones a gente que quiere obtener una posición en un departamento, un aumento de suelo - en definitiva: un trabajo, y están dispuestos a pagar por ello. En mi opinión, como estudiantes de doctorado: no os preocupeis sobre revistas depredadoras, son simplemente cortinas de humo detrás del verdadero problema de la ciencia: ¿cómo negociamos la tensión entre la supuesta búsqueda por la verdad objetiva, independiente, imparcial, con otra verdad –que los científicos comen, beben, y necesitan un salario para pagar el alquiler? Eso, sin embargo, es otra cuestión que es digna de ser abordada directamente. 

Se suponía que yo debería venir aquí a hablar de resultados negativos, pero la verdad, pensé que sería más interesante para vosotros, que muchos de vosotros teneis que hacer este webinar porque es una obligación de vuestra escuela de doctorado, hablaros de estos asuntos. Pero también quiero aprovechar para hablaros brevemente de resultados negativos. En el proceso del que hemos hablado sobre devaluación del artículo científico como unidad de comuniacación y sobreevauación como unidad de contabilidad, hemos perdido algo. Hemos perdido la posibilidad de representar lo que el *proceso* cientifico realmente es. Y eso es, ensayo y error. Equivocación, estimación, y fallo. Mucha de la ciencia es eso: precisamente de eso se trata *in-ves-ti-gar*: intentar describir lo desconocido. En el proceso de devaluación, el artículo ha dejado de ser un relato de un experimento, a todo lo contrario. Millones de experimentos distintos, de distintas ciencias, se ven sometidos a ser enmarcados en un formato único: INTRODUCCIÓN, MÉTODOS, RESULTADOS, DISCUSSIÓN. Además, dentro de esta obsessión por enmarcar toda la ciencia en estas cuatro palabras, hay otro problema. Que nadie publica todos esos experimentos que no van como uno esperaba. En la ciencia actual, hay un grave problema con una sobresaturación de resultados positivos (positivos entendidos aquí como p<0.05), lo que de por sí, ya es una señal que hay mucho que se queda en el tintero. ¿Porqué os cuento esto? Porque soy unos de los fundadores del *Journal of Trial and Error,* la revista de ensayo y error: una revista dedicada a *todos* los ámbitos de la investigación, dedicada a publicar 'fallos' o resultados negativos, y con un espíritu crítico y reflexivo. No tengo más tiempo de hablar de estó aquí, pero podeis checkear nuestra web: jtrialerror.com. Revista Diamond Open Access (no cuesta nada ni publicar, ni leer), gracias al financiamento público e instituticional de la Universidad de Utrecht. 

Finalizando, me gustaría daros recomendaciones más concretas:

1. Open Access in not Open Science
	- cuando cobran 9500 euros por una publicación en abierto, es una violación directa de los principios del open science
2. Sci-hub: funciona si pones sci-hub.??/DOI
3. Open Science no debe ser el objectivo, pero el medio. En mi opinión, lo único realmente positivo de la ciencia abierta es que 1. invita a la auto-relfexión, 2. crea la posibilidad de organización *entre* científicos de base gracias al poder decrentralizador de internet.
4. Las revistas depredadoras no son un problema
5. La ciencia es un sistema social, político, y cultural, por lo que es necesario la auto-organización, hacer presión política más allá de pedir más dinero para ciencia, y establecer nucleos de resistencia, como las bibiliotecas de universidades que se están uniendo rechazando los 9500 euros de APCs del nuevo modelo de Nature de Open Access
6. Hay que reforzar el modelo de publicaciones de sociedades y abandonar el modelo comercial de publicaciones académicas.
7. Y por último: la publicación científica no es una unidad de comunicación o de conocimiento, la publicación científica es una unidad de evaluación y de contabilidad.

Cómo creo que habreís podido ver, soy un poco reticente a aceptar a viva voz que la Ciencia Abierta es todo lo que la ciencia necesita. Soy crítico y escéptico de la Ciencia Abierta realmente provocando cambios significativos que preocupan hoy en día a los científicos (el mayor de ellos siendo la posibilidad de labrar una carrera científica). Soy escéptico porque los mismos procesos que han causado la crisis de publicación académica, la inestabilidad laboral, y el creciente ímpetu evaluador en las universidades, son los que han facilitado el nacimiento del Open Science, el Open Access,  y los altmetrics. Que no te dejen convencer aquellos que han labrado una carrera antes de los años 90 y que ahora ven aquello que brilla en el Open Science. Las cosas que no brillavan entonces siguen estando presente hoy, incluso, en mi opinión, peor, o al menos, con otra forma. Las cosas eran muy diferentes antes de los años 90. Nuestro camino es distinto al suyo. Si queremos cambio, va a hacer falta más que abrir la ciencia, va hacer falta reconstruirla.